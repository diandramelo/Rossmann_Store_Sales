{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 0. IMPORTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## 0.1. Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T09:36:45.823725Z",
     "start_time": "2020-11-17T09:36:44.637455Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import inflection\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "\n",
    "from IPython.display       import Image\n",
    "from matplotlib            import gridspec\n",
    "from tabulate              import tabulate\n",
    "from scipy.stats           import chi2_contingency\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler, LabelEncoder\n",
    "from boruta                import BorutaPy\n",
    "from sklearn.ensemble      import RandomForestRegressor\n",
    "from sklearn.metrics       import mean_absolute_error, mean_squared_error\n",
    "from sklearn.linear_model  import LinearRegression, Lasso\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## 0.2. Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T09:36:45.834246Z",
     "start_time": "2020-11-17T09:36:45.825975Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def cramer_v(x,y):\n",
    "    cm = pd.crosstab(x, y).values\n",
    "    n = cm.sum()\n",
    "    r, k = cm.shape\n",
    "    chi2 = chi2_contingency (cm )[0]\n",
    "    \n",
    "    chi2corr = max(0, chi2 - (k-1)*(r-1)/(n-1))\n",
    "    \n",
    "    kcorr = k - (k-1)**2/(n-1)\n",
    "    \n",
    "    rcorr = r - (r-1)**2/(n-1)\n",
    "    \n",
    "    return np.sqrt( (chi2corr/n) / (min(kcorr-1, rcorr-1 )))\n",
    "\n",
    "def mean_absolute_percentage_error (y, yhat):\n",
    "    return np.mean(np.abs((y - yhat) / y))\n",
    "\n",
    "def ml_error (model_name, y, yhat):\n",
    "    mae = mean_absolute_error(y, yhat)\n",
    "    mape = mean_absolute_percentage_error(y, yhat)\n",
    "    rmse = np.sqrt(mean_squared_error(y, yhat))\n",
    "    return pd.DataFrame({ 'Model Name': model_name,\n",
    "                          'MAE': mae,\n",
    "                          'MAPE': mape,\n",
    "                          'RMSE': rmse}, index = [0])\n",
    "\n",
    "def cross_validation (x_training, kfold, model_name, model, verbose=False):\n",
    "    # error lists creation\n",
    "    mae_list = []\n",
    "    mape_list = []\n",
    "    rmse_list = []\n",
    "\n",
    "    for k in reversed(range(1, kfold+1)):\n",
    "        if verbose:\n",
    "            print('\\nKfold Number: {}'.format( k ) )\n",
    "            \n",
    "        # filtering dataset\n",
    "        validation_start_date = x_training['date'].max() - datetime.timedelta(days = k*6*7)\n",
    "        validation_end_date = x_training['date'].max() - datetime.timedelta(days = (k-1)*6*7)\n",
    "\n",
    "        validation = x_training[(x_training['date'] >= validation_start_date) & (x_training['date'] <= validation_end_date)]\n",
    "        training = x_training[x_training['date'] < validation_start_date]\n",
    "\n",
    "        # training dataset\n",
    "        xtraining = training.drop(['date', 'sales'], axis = 1)\n",
    "        ytraining = training['sales']\n",
    "\n",
    "        # validation dataset\n",
    "        xvalidation = validation.drop(['date', 'sales'], axis = 1)\n",
    "        yvalidation = validation['sales']\n",
    "\n",
    "        ## model\n",
    "        m = model.fit(xtraining, ytraining)\n",
    "\n",
    "        ## prediction\n",
    "        yhat = m.predict(xvalidation)\n",
    "\n",
    "        ## performance\n",
    "        m_result = ml_error(model_name, np.expm1(yvalidation), np.expm1(yhat))\n",
    "\n",
    "        # error lists value addition\n",
    "        mae_list.append(m_result['MAE'])\n",
    "        mape_list.append(m_result['MAPE'])\n",
    "        rmse_list.append(m_result['RMSE'])\n",
    "\n",
    "    \n",
    "    return pd.DataFrame({'Model Name': model_name,\n",
    "                         'MAE': np.round(np.mean(mae_list)).astype(str) + '+/-' + np.round(np.std(mae_list)).astype(str),\n",
    "                         'MAPE': np.round(np.mean(mape_list)).astype(str) + '+/-' + np.round(np.std(mape_list)).astype(str),\n",
    "                         'RSME': np.round(np.mean(rmse_list)).astype(str) + '+/-' + np.round(np.std(rmse_list)).astype(str)}, index=[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## 0.3. Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T09:36:47.059974Z",
     "start_time": "2020-11-17T09:36:45.838481Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_sales_raw = pd.read_csv('data/train.csv', low_memory=False)\n",
    "df_store_raw = pd.read_csv('data/store.csv', low_memory=False)\n",
    "\n",
    "# merge\n",
    "df_raw = pd.merge(df_sales_raw, df_store_raw, how='left', on = 'Store')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## 0.4. Graph Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T09:36:47.096179Z",
     "start_time": "2020-11-17T09:36:47.062970Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "\n",
    "def jupyter_settings():\n",
    "   %matplotlib inline\n",
    "   %pylab inline\n",
    "   plt.style.use( 'bmh' )\n",
    "   plt.rcParams['figure.figsize'] = [18, 8]\n",
    "   plt.rcParams['font.size'] = 20\n",
    "   display( HTML( '<style>.container { width:100% !important; }</style>') )\n",
    "   pd.options.display.max_columns = None\n",
    "   pd.options.display.max_rows = None\n",
    "   pd.set_option( 'display.expand_frame_repr', False )\n",
    "   sns.set()\n",
    "    \n",
    "jupyter_settings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 1. DESCRIBE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T09:36:47.204990Z",
     "start_time": "2020-11-17T09:36:47.099555Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df1 = df_raw.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## 1.1. Rename Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T09:36:47.216480Z",
     "start_time": "2020-11-17T09:36:47.206869Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# list(df1.columns)\n",
    "\n",
    "cols_old = ['Store', 'DayOfWeek', 'Date', 'Sales', 'Customers', 'Open', 'Promo', 'StateHoliday',\n",
    "            'SchoolHoliday', 'StoreType', 'Assortment', 'CompetitionDistance', 'CompetitionOpenSinceMonth',\n",
    "            'CompetitionOpenSinceYear', 'Promo2', 'Promo2SinceWeek', 'Promo2SinceYear', 'PromoInterval']\n",
    "\n",
    "# CamelCase to SnakeCase\n",
    "snakecase = lambda x: inflection.underscore(x)\n",
    "\n",
    "cols_new = list( map( snakecase, cols_old ) )\n",
    "\n",
    "# rename\n",
    "df1.columns = cols_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T09:33:35.396883Z",
     "start_time": "2020-11-09T09:33:35.394146Z"
    },
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## 1.2. Data Dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T09:36:47.226652Z",
     "start_time": "2020-11-17T09:36:47.221545Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Rows: 1017209\n",
      "Number of Columns: 18\n"
     ]
    }
   ],
   "source": [
    "print('Number of Rows: {}'.format(df1.shape[0]))\n",
    "print('Number of Columns: {}'.format(df1.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## 1.3. Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T09:36:47.473012Z",
     "start_time": "2020-11-17T09:36:47.230870Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>date</th>\n",
       "      <th>sales</th>\n",
       "      <th>customers</th>\n",
       "      <th>open</th>\n",
       "      <th>promo</th>\n",
       "      <th>state_holiday</th>\n",
       "      <th>school_holiday</th>\n",
       "      <th>store_type</th>\n",
       "      <th>assortment</th>\n",
       "      <th>competition_distance</th>\n",
       "      <th>competition_open_since_month</th>\n",
       "      <th>competition_open_since_year</th>\n",
       "      <th>promo2</th>\n",
       "      <th>promo2_since_week</th>\n",
       "      <th>promo2_since_year</th>\n",
       "      <th>promo_interval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>607248</th>\n",
       "      <td>359</td>\n",
       "      <td>5</td>\n",
       "      <td>2014-01-03</td>\n",
       "      <td>6393</td>\n",
       "      <td>595</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>d</td>\n",
       "      <td>c</td>\n",
       "      <td>4370.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        store  day_of_week        date  sales  customers  open  promo state_holiday  school_holiday store_type assortment  competition_distance  competition_open_since_month  competition_open_since_year  promo2  promo2_since_week  promo2_since_year promo_interval\n",
       "607248    359            5  2014-01-03   6393        595     1      0             0               1          d          c                4370.0                           NaN                          NaN       0                NaN                NaN            NaN"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T09:36:47.629838Z",
     "start_time": "2020-11-17T09:36:47.475073Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "store                                    int64\n",
       "day_of_week                              int64\n",
       "date                            datetime64[ns]\n",
       "sales                                    int64\n",
       "customers                                int64\n",
       "open                                     int64\n",
       "promo                                    int64\n",
       "state_holiday                           object\n",
       "school_holiday                           int64\n",
       "store_type                              object\n",
       "assortment                              object\n",
       "competition_distance                   float64\n",
       "competition_open_since_month           float64\n",
       "competition_open_since_year            float64\n",
       "promo2                                   int64\n",
       "promo2_since_week                      float64\n",
       "promo2_since_year                      float64\n",
       "promo_interval                          object\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['date'] = pd.to_datetime(df1['date'])\n",
    "df1.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## 1.4. Check NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T09:36:47.866467Z",
     "start_time": "2020-11-17T09:36:47.632158Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "store                                0\n",
       "day_of_week                          0\n",
       "date                                 0\n",
       "sales                                0\n",
       "customers                            0\n",
       "open                                 0\n",
       "promo                                0\n",
       "state_holiday                        0\n",
       "school_holiday                       0\n",
       "store_type                           0\n",
       "assortment                           0\n",
       "competition_distance              2642\n",
       "competition_open_since_month    323348\n",
       "competition_open_since_year     323348\n",
       "promo2                               0\n",
       "promo2_since_week               508031\n",
       "promo2_since_year               508031\n",
       "promo_interval                  508031\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## 1.5. Fillout NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T09:36:50.471417Z",
     "start_time": "2020-11-17T09:36:47.868963Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-669cc2e20aaf>:18: FutureWarning: Series.dt.weekofyear and Series.dt.week have been deprecated.  Please use Series.dt.isocalendar().week instead.\n",
      "  df1['promo2_since_week'] = df1['promo2_since_week'].fillna(df1['date'].dt.week)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-669cc2e20aaf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;31m# New variable: check if sales date was in the period of promotion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m \u001b[0mdf1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'is_promo'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'promo_interval'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'month_map'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'promo_interval'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'month_map'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'promo_interval'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m','\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/3.8.0/envs/RossmannStoreSales/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwds)\u001b[0m\n\u001b[1;32m   7550\u001b[0m             \u001b[0mkwds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7551\u001b[0m         )\n\u001b[0;32m-> 7552\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7554\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapplymap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"DataFrame\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.0/envs/RossmannStoreSales/lib/python3.8/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_empty_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.0/envs/RossmannStoreSales/lib/python3.8/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m         \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0;31m# wrap results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.0/envs/RossmannStoreSales/lib/python3.8/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    298\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m                     \u001b[0;31m# ignore SettingWithCopy here in case the user mutates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m                     \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m                         \u001b[0;31m# If we have a view on v, we need to make a copy because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# competition_distance (2642 NAs)\n",
    "\n",
    "# df1['competition_distance'].max() = 75860.0\n",
    "\n",
    "df1['competition_distance'] = df1['competition_distance'].fillna(200000)\n",
    "\n",
    "\n",
    "# competition_open_since_month (323348 NAs)\n",
    "df1['competition_open_since_month'] = df1['competition_open_since_month'].fillna(df1['date'].dt.month)\n",
    "# similarly: df1['competition_open_since_month'] = df1.apply( lambda x: x['date'].month if math.isnan( x['competition_open_since_month'] ) else x['competition_open_since_month'], axis=1 )\n",
    "\n",
    "\n",
    "# competition_open_since_year (323348 NAs)\n",
    "df1['competition_open_since_year'] = df1['competition_open_since_year'].fillna(df1['date'].dt.year)\n",
    "\n",
    "\n",
    "# promo2_since_week (508031 NAs)\n",
    "df1['promo2_since_week'] = df1['promo2_since_week'].fillna(df1['date'].dt.week)\n",
    "\n",
    "\n",
    "# promo2_since_year (508031 NAs)\n",
    "df1['promo2_since_year'] = df1['promo2_since_year'].fillna(df1['date'].dt.year)\n",
    "\n",
    "\n",
    "# promo_interval (508031 NAs)\n",
    "month_map = {1: 'Jan',\n",
    "             2: 'Feb',\n",
    "             3: 'Mar',\n",
    "             4: 'Apr',\n",
    "             5: 'May',\n",
    "             6: 'Jun',\n",
    "             7: 'Jul',\n",
    "             8: 'Aug',\n",
    "             9: 'Sep',\n",
    "             10: 'Oct',\n",
    "             11: 'Nov',\n",
    "             12: 'Dec'}\n",
    "\n",
    "df1['promo_interval'].fillna(0, inplace=True )\n",
    "\n",
    "df1['month_map'] = df1['date'].dt.month.map( month_map )\n",
    "\n",
    "# New variable: check if sales date was in the period of promotion\n",
    "df1['is_promo'] = df1[['promo_interval', 'month_map']].apply( lambda x: 0 if x['promo_interval'] == 0 else 1 if x['month_map'] in x['promo_interval'].split( ',' ) else 0, axis=1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## 1.6. Change Data Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T09:36:50.475983Z",
     "start_time": "2020-11-17T09:36:44.728Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# competition\n",
    "df1['competition_open_since_month'] = df1['competition_open_since_month'].astype(int)\n",
    "df1['competition_open_since_year'] = df1['competition_open_since_year'].astype(int)\n",
    "    \n",
    "# promo2\n",
    "df1['promo2_since_week'] = df1['promo2_since_week'].astype(int)\n",
    "df1['promo2_since_year'] = df1['promo2_since_year'].astype(int)\n",
    "\n",
    "df1.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## 1.7. Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T09:36:50.477072Z",
     "start_time": "2020-11-17T09:36:44.737Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "num_attributes = df1.select_dtypes(include = ['int64', 'float64'])\n",
    "cat_attributes = df1.select_dtypes(exclude = ['int64', 'float64', 'datetime64[ns]'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### 1.7.1. Numerical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T09:36:50.478218Z",
     "start_time": "2020-11-17T09:36:44.745Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Central Tendency - Mean, Median\n",
    "ct1 = pd.DataFrame(num_attributes.mean())\n",
    "ct2 = pd.DataFrame(num_attributes.median())\n",
    "\n",
    "# Dispersion - Std, Min, Max, Range, Skew, Kurtosis\n",
    "d1 = pd.DataFrame(num_attributes.std())\n",
    "d2 = pd.DataFrame(num_attributes.min())\n",
    "d3 = pd.DataFrame(num_attributes.max())\n",
    "d4 = pd.DataFrame(num_attributes.max() - num_attributes.min())\n",
    "d5 = pd.DataFrame(num_attributes.skew())\n",
    "d6 = pd.DataFrame(num_attributes.kurtosis())\n",
    "\n",
    "# concat\n",
    "df_num = pd.concat([ct1, ct2, d1, d2, d3, d4, d5, d6], axis = 1)\n",
    "df_num.columns = ['mean', 'median', 'std', 'min', 'max', 'range', 'skew', 'kurtosis']\n",
    "df_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T09:36:50.480047Z",
     "start_time": "2020-11-17T09:36:44.753Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sns.displot(df1['competition_distance'], kde = False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### 1.7.2. Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T09:36:50.481358Z",
     "start_time": "2020-11-17T09:36:44.761Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cat_attributes.apply( lambda x: x.unique().shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T09:36:50.482479Z",
     "start_time": "2020-11-17T09:36:44.767Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "aux1 = df1[(df1['state_holiday'] != '0') & (df1['sales'] > 0)] # filtering data for better visualization\n",
    "\n",
    "plt.subplot(1,3,1)\n",
    "sns.boxplot(x = 'state_holiday', y = 'sales', data = aux1);\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "sns.boxplot(x = 'store_type', y = 'sales', data = aux1);\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "sns.boxplot(x = 'assortment', y = 'sales', data = aux1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 2. FEATURE ENGINEERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T09:36:50.483581Z",
     "start_time": "2020-11-17T09:36:44.773Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df2 = df1.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## 2.1. Hypothesis Mind Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T09:36:50.484603Z",
     "start_time": "2020-11-17T09:36:44.779Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Image(filename='Daily_Store_Sales.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## 2.2. Hypothesis Development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Creation of hypothesis for each category in the Mind Map, while related to the response variable << **sales** >> .\n",
    "\n",
    "PS.: Clients & Location: none information on dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T08:42:13.115001Z",
     "start_time": "2020-11-10T08:42:13.111972Z"
    },
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### 2.2.1. Store Hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**1.** Stores with **more diversified products** should sell **more**\n",
    "\n",
    "**2.** Stores with **closer competitors** should sell **less**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T08:42:13.115001Z",
     "start_time": "2020-11-10T08:42:13.111972Z"
    },
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### 2.2.2. Product Hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**1.** Stores with **longer active promotions** should sell **more**\n",
    "\n",
    "**2.** Stores with **more consecutive promotions** should sell **more**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T08:42:13.115001Z",
     "start_time": "2020-11-10T08:42:13.111972Z"
    },
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### 2.2.3. Time Series Hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**1.** Stores, during **school holidays**, should sell **more**\n",
    "\n",
    "**2.** Stores, in **Christmas period**, should sell **more** than during other holidays\n",
    "\n",
    "**3.** Stores, during **weekends**, should sell **less**\n",
    "\n",
    "**4.** At the **first half of the month**, stores should sell **more**\n",
    "\n",
    "**5** In the **first semester of the year**, stores should sell **less**\n",
    "\n",
    "**6.** **Throughout the years**, stores should sell **more**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## 2.3. Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### 2.3.1. Created Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T09:36:50.485577Z",
     "start_time": "2020-11-17T09:36:44.792Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T09:36:50.486575Z",
     "start_time": "2020-11-17T09:36:44.796Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# year\n",
    "df2['year'] = df2['date'].dt.year\n",
    "\n",
    "# month\n",
    "df2['month'] = df2['date'].dt.month\n",
    "\n",
    "# day\n",
    "df2['day'] = df2['date'].dt.day\n",
    "\n",
    "# week_of_year\n",
    "df2['week_of_year'] = df2['date'].dt.week\n",
    "\n",
    "# year_week\n",
    "df2['year_week'] = df2['date'].dt.strftime('%Y-%W')\n",
    "\n",
    "###\n",
    "\n",
    "# competition_since\n",
    "df2['competition_since'] = df2.apply(lambda x: datetime.datetime(year = x['competition_open_since_year'], month = x['competition_open_since_month'], day = 1), axis = 1)\n",
    "df2['competition_time_month'] = ((df2['date'] - df2['competition_since'])/30).apply(lambda x: x.days).astype(int)\n",
    "\n",
    "# promo_since\n",
    "df2['promo_since'] = df2['promo2_since_year'].astype(str) + '-' + df2['promo2_since_week'].astype(str)\n",
    "df2['promo_since'] = df2['promo_since'].apply(lambda x: datetime.datetime.strptime(x + '-1', '%Y-%W-%w') - datetime.timedelta(days = 7))\n",
    "df2['promo_time_week'] = ((df2['date'] - df2['promo_since'])/7).apply(lambda x: x.days).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### 2.3.2. Modified Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T09:36:50.487500Z",
     "start_time": "2020-11-17T09:36:44.801Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# state_holiday\n",
    "df2['state_holiday'] = df2['state_holiday'].apply(lambda x: 'public_holiday' if x == 'a' else 'easter_holiday' if x == 'b' else 'christmas' if x == 'c' else 'regular_day')\n",
    "\n",
    "# assortment\n",
    "df2['assortment'] = df2['assortment'].apply(lambda x: 'basic' if x == 'a' else 'extra' if x == 'b' else 'extended')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 3. FILTERING VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T09:36:50.488526Z",
     "start_time": "2020-11-17T09:36:44.807Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df3 = df2.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## 3.1. Filtering Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T09:36:50.489589Z",
     "start_time": "2020-11-17T09:36:44.813Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df3 = df3[(df3['open'] != 0) & (df3['sales'] > 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## 3.2. Columns Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T09:36:50.490538Z",
     "start_time": "2020-11-17T09:36:44.819Z"
    },
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cols_drop = ['customers', 'open', 'promo_interval', 'month_map']\n",
    "df3 = df3.drop(cols_drop, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 4. EXPLORATORY DATA ANALYSIS (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T09:36:50.491520Z",
     "start_time": "2020-11-17T09:36:44.825Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df4 = df3.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## 4.1. Univariate Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### 4.1.1. Response Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T09:36:50.492663Z",
     "start_time": "2020-11-17T09:36:44.831Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.distplot(df4['sales']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### 4.1.2. Numerical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T09:36:50.493653Z",
     "start_time": "2020-11-17T09:36:44.837Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_attributes.hist(bins = 25);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### 4.1.3. Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T09:36:50.494666Z",
     "start_time": "2020-11-17T09:36:44.842Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# state_holiday\n",
    "aux1 = df4[df4['state_holiday'] != 'regular_day']\n",
    "\n",
    "plt.subplot(3, 2, 1)\n",
    "sns.countplot(aux1['state_holiday']);\n",
    "\n",
    "plt.subplot(3, 2, 2)\n",
    "sns.kdeplot(df4[df4['state_holiday'] == 'public_holiday']['sales'], shade = True, label = 'public_holiday');\n",
    "sns.kdeplot(df4[df4['state_holiday'] == 'easter_holiday']['sales'], shade = True, label = 'easter_holiday');\n",
    "sns.kdeplot(df4[df4['state_holiday'] == 'christmas']['sales'], shade = True, label = 'christmas');\n",
    "plt.legend();\n",
    "\n",
    "\n",
    "# store_type\n",
    "plt.subplot(3, 2, 3)\n",
    "sns.countplot(df4['store_type']);\n",
    "\n",
    "plt.subplot(3, 2, 4)\n",
    "sns.kdeplot(df4[df4['store_type'] == 'a']['sales'], shade = True, label = 'a');\n",
    "sns.kdeplot(df4[df4['store_type'] == 'b']['sales'], shade = True, label = 'b');\n",
    "sns.kdeplot(df4[df4['store_type'] == 'c']['sales'], shade = True, label = 'c');\n",
    "sns.kdeplot(df4[df4['store_type'] == 'd']['sales'], shade = True, label = 'd');\n",
    "plt.legend();\n",
    "\n",
    "\n",
    "# assortment\n",
    "plt.subplot(3, 2, 5)\n",
    "sns.countplot(df4['assortment']);\n",
    "\n",
    "plt.subplot(3, 2, 6)\n",
    "sns.kdeplot(df4[df4['assortment'] == 'basic']['sales'], shade = True, label = 'basic');\n",
    "sns.kdeplot(df4[df4['assortment'] == 'extra']['sales'], shade = True, label = 'extra');\n",
    "sns.kdeplot(df4[df4['assortment'] == 'extended']['sales'], shade = True, label = 'extended');\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## 4.2. Bivariate Analysis - Hypothesis Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### 4.2.1. Individual Analysis of the Hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T10:28:48.476678Z",
     "start_time": "2020-11-10T10:28:48.464923Z"
    },
    "hidden": true
   },
   "source": [
    "**H1.** Stores with **more diversified products** should sell **more**\n",
    "\n",
    "**TRUE**, when compared to basic assortment, although extended assortment does not sell more than extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T09:36:50.495651Z",
     "start_time": "2020-11-17T09:36:44.852Z"
    },
    "hidden": true,
    "hide_input": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "aux1 = df4[['assortment', 'sales']].groupby('assortment').mean().reset_index()\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.barplot(x = 'assortment', y = 'sales', data = aux1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T10:28:48.476678Z",
     "start_time": "2020-11-10T10:28:48.464923Z"
    },
    "hidden": true,
    "hide_input": false
   },
   "source": [
    "**H2.** Stores with **closer competitors** should sell **less**\n",
    "\n",
    "**FALSE** - sales do not vary much"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T09:36:50.496689Z",
     "start_time": "2020-11-17T09:36:44.857Z"
    },
    "hidden": true,
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "aux1 = df4[['competition_distance', 'sales']].groupby('competition_distance').mean().reset_index()\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "bins = list(np.arange(0,20000,1000))\n",
    "aux1['competition_distance_binned'] = pd.cut(aux1['competition_distance'], bins = bins)\n",
    "aux2 = aux1[['competition_distance_binned', 'sales']].groupby('competition_distance_binned').mean().reset_index()\n",
    "sns.barplot(x = 'competition_distance_binned', y = 'sales', data = aux2);\n",
    "plt.xticks(rotation = 90);\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "sns.scatterplot(x = 'competition_distance', y = 'sales', data = aux1);\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "sns.heatmap(aux1.corr(method = 'pearson'), annot = True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T10:28:48.476678Z",
     "start_time": "2020-11-10T10:28:48.464923Z"
    },
    "hidden": true
   },
   "source": [
    "**H3.** Stores with **longer active promotions** should sell **more**\n",
    "\n",
    "**TRUE** - There is a tendency of more average sales for stores with longer periods of promotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T09:36:50.498128Z",
     "start_time": "2020-11-17T09:36:44.862Z"
    },
    "hidden": true,
    "hide_input": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "aux1 = df4[['promo_time_week', 'sales']].groupby('promo_time_week').mean().reset_index()\n",
    "\n",
    "grid = gridspec.GridSpec(2,3)\n",
    "\n",
    "\n",
    "# extended promotion\n",
    "aux2 = aux1.loc[(aux1['promo_time_week'] >= 0), :]\n",
    "\n",
    "plt.subplot(grid[0,0])\n",
    "bins = list(np.arange(0,313,20))\n",
    "aux2['promo_time_week_binned'] = pd.cut(aux2['promo_time_week'], bins = bins)\n",
    "aux3 = aux2[['promo_time_week_binned', 'sales']].groupby('promo_time_week_binned').mean().reset_index()\n",
    "sns.barplot(x = 'promo_time_week_binned', y = 'sales', data = aux3);\n",
    "plt.xticks(rotation = 90);\n",
    "\n",
    "plt.subplot(grid[0,1])\n",
    "sns.regplot(x = 'promo_time_week', y = 'sales', data = aux2);\n",
    "\n",
    "\n",
    "# regular promotion\n",
    "aux4 = aux1[aux1['promo_time_week'] < 0]\n",
    "\n",
    "plt.subplot(grid[1,0])\n",
    "bins = list(np.arange(-126,0,5))\n",
    "aux4['promo_time_week_binned'] = pd.cut(aux4['promo_time_week'], bins = bins)\n",
    "aux5 = aux4[['promo_time_week_binned', 'sales']].groupby('promo_time_week_binned').mean().reset_index()\n",
    "sns.barplot(x = 'promo_time_week_binned', y = 'sales', data = aux5);\n",
    "plt.xticks(rotation = 90);\n",
    "\n",
    "plt.subplot(grid[1,1])\n",
    "sns.regplot(x = 'promo_time_week', y = 'sales', data = aux4);\n",
    "\n",
    "\n",
    "plt.subplot(grid[:,2])\n",
    "sns.heatmap(aux1.corr(method = 'pearson'), annot = True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T10:28:48.476678Z",
     "start_time": "2020-11-10T10:28:48.464923Z"
    },
    "hidden": true
   },
   "source": [
    "**H4.** Stores with **more consecutive promotions** should sell **more**\n",
    "\n",
    "**FALSE** - Stores with regular promotions only sell more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T09:36:50.499225Z",
     "start_time": "2020-11-17T09:36:44.868Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df4[['promo', 'promo2', 'sales']].groupby(['promo', 'promo2']).mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T09:36:50.500182Z",
     "start_time": "2020-11-17T09:36:44.873Z"
    },
    "hidden": true,
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "aux1 = df4[(df4['promo'] == 1) & (df4['promo2'] == 1)][['year_week', 'sales']].groupby('year_week').mean().reset_index()\n",
    "ax = aux1.plot();\n",
    "\n",
    "aux2 = df4[(df4['promo'] == 1) & (df4['promo2'] == 0)][['year_week', 'sales']].groupby('year_week').mean().reset_index()\n",
    "aux2.plot(ax=ax);\n",
    "\n",
    "ax.legend(labels=['Regular + Extended', 'Regular']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T10:28:48.476678Z",
     "start_time": "2020-11-10T10:28:48.464923Z"
    },
    "hidden": true
   },
   "source": [
    "**H5.** Stores, during **school holidays**, should sell **more**\n",
    "\n",
    "**TRUE**, except for the months of January, April, November and December"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T09:36:50.504462Z",
     "start_time": "2020-11-17T09:36:44.879Z"
    },
    "hidden": true,
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "aux1 = df4[['school_holiday', 'sales']].groupby('school_holiday').mean().reset_index()\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "sns.barplot(x = 'school_holiday', y = 'sales', data = aux1);\n",
    "\n",
    "# analysis per month\n",
    "plt.subplot(2, 1, 2)\n",
    "aux2 = df4[['school_holiday', 'month', 'sales']].groupby(['school_holiday', 'month']).mean().reset_index()\n",
    "sns.barplot(x = 'month', y = 'sales', hue = 'school_holiday', data = aux2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T10:28:48.476678Z",
     "start_time": "2020-11-10T10:28:48.464923Z"
    },
    "hidden": true
   },
   "source": [
    "**H6.** Stores, in **Christmas period**, should sell **more** than during other holidays\n",
    "\n",
    "**FALSE** - Stores sell less in Christmas than in public holiday or easter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T09:36:50.507252Z",
     "start_time": "2020-11-17T09:36:44.885Z"
    },
    "hidden": true,
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "# 2015 removed - data is only until 31/07/2015\n",
    "\n",
    "aux1 = df4[(df4['state_holiday'] != 'regular_day') & (df4['year'] < 2015)]\n",
    "\n",
    "aux2 = aux1[['state_holiday', 'year', 'sales']].groupby(['year', 'state_holiday']).mean().reset_index()\n",
    "\n",
    "sns.barplot(x = 'state_holiday', y = 'sales', hue = 'year', data = aux2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T10:28:48.476678Z",
     "start_time": "2020-11-10T10:28:48.464923Z"
    },
    "hidden": true
   },
   "source": [
    "**H7.** Stores, during **weekends**, should sell **less**\n",
    "\n",
    "**TRUE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T09:36:50.510957Z",
     "start_time": "2020-11-17T09:36:44.894Z"
    },
    "hidden": true,
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "aux1 = df4[['day_of_week', 'sales']].groupby('day_of_week').sum().reset_index()\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.barplot(x = 'day_of_week', y = 'sales', data = aux1);\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.heatmap(aux1.corr(method = 'pearson'), annot = True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T10:28:48.476678Z",
     "start_time": "2020-11-10T10:28:48.464923Z"
    },
    "hidden": true
   },
   "source": [
    "**H8.** At the **first half of the month**, stores should sell **more**\n",
    "\n",
    "**TRUE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T09:36:50.513372Z",
     "start_time": "2020-11-17T09:36:44.903Z"
    },
    "hidden": true,
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "aux1 = df4[['day', 'sales']].groupby('day').sum().reset_index()\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "sns.barplot(x = 'day', y = 'sales', data = aux1);\n",
    "plt.xticks(rotation = 90);\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "sns.regplot(x = 'day', y = 'sales', data = aux1);\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "sns.heatmap(aux1.corr(method = 'pearson'), annot = True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T10:28:48.476678Z",
     "start_time": "2020-11-10T10:28:48.464923Z"
    },
    "hidden": true
   },
   "source": [
    "**H9.** In the **first semester of the year**, stores should sell **less**\n",
    "\n",
    "**TRUE** - Analysis for the years of 2013 and 2014 (the data from 2015 stops in july)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T09:36:50.516115Z",
     "start_time": "2020-11-17T09:36:44.910Z"
    },
    "hidden": true,
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "# 2015 removed - data only until 31/07/2015\n",
    "\n",
    "aux = df4[df4['year'] < 2015]\n",
    "\n",
    "aux1 = aux[['month', 'sales']].groupby('month').sum().reset_index()\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "sns.barplot(x = 'month', y = 'sales', data = aux1);\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "sns.regplot(x = 'month', y = 'sales', data = aux1);\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "sns.heatmap(aux1.corr(method = 'pearson'), annot = True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**H10.** **Throughout the years**, stores should sell **more**\n",
    "\n",
    "**FALSE** - Even though data of 2015 is incomplete, it was considered to observe the tendency of sales reduction throughout years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T09:36:50.518055Z",
     "start_time": "2020-11-17T09:36:44.916Z"
    },
    "hidden": true,
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "aux1 = df4[['year', 'sales']].groupby('year').sum().reset_index()\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "sns.barplot(x = 'year', y = 'sales', data = aux1);\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "sns.regplot(x = 'year', y = 'sales', data = aux1);\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "sns.heatmap(aux1.corr(method = 'pearson'), annot = True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### 4.2.2. General Hypothesis Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T09:36:50.520100Z",
     "start_time": "2020-11-17T09:36:44.921Z"
    },
    "hidden": true,
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "\n",
    "tab = [['Hypothesis', 'Conclusion', 'Relevance'],\n",
    "       ['H1 - Stores with more diversified products should sell more', 'True', 'Medium'],\n",
    "       ['H2 - Stores with closer competitors should sell less', 'False', 'Low'],\n",
    "       ['H3 - Stores with longer active promotions should sell more', 'True', 'Medium'],\n",
    "       ['H4 - Stores with more consecutive promotions should sell more', 'False', 'Low'],\n",
    "       ['H5 - Stores, during school holidays, should sell more', 'True', 'Low'],\n",
    "       ['H6 - Stores, in Christmas period, should sell more than during other holidays', 'False', 'Medium'],\n",
    "       ['H7 - Stores, during weekends, should sell less', 'True', 'High'],\n",
    "       ['H8 - At the first half of the month, stores should sell more', 'True', 'High'],\n",
    "       ['H9 - In the first semester of the year, stores should sell less', 'True', 'High'],\n",
    "       ['H10 - Throughout the years, stores should sell more', 'False', 'High']\n",
    "      ]\n",
    "print(tabulate(tab, headers='firstrow'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## 4.3. Multivariate Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### 4.3.1. Numerical Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T09:36:50.521966Z",
     "start_time": "2020-11-17T09:36:44.928Z"
    },
    "hidden": true,
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "sns.heatmap(num_attributes.corr(method = 'pearson'), annot = True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### 4.3.2. Categorical Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T09:36:50.523870Z",
     "start_time": "2020-11-17T09:36:44.933Z"
    },
    "hidden": true,
    "hide_input": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "a = df4.select_dtypes(include='object')\n",
    "\n",
    "# calculating cramer v\n",
    "a1 = cramer_v(a['state_holiday'], a['state_holiday'])\n",
    "a2 = cramer_v(a['state_holiday'], a['store_type'])\n",
    "a3 = cramer_v(a['state_holiday'], a['assortment'])\n",
    "\n",
    "a4 = cramer_v(a['store_type'], a['state_holiday'])\n",
    "a5 = cramer_v(a['store_type'], a['store_type'])\n",
    "a6 = cramer_v(a['store_type'], a['assortment'])\n",
    "\n",
    "a7 = cramer_v(a['assortment'], a['state_holiday'])\n",
    "a8 = cramer_v(a['assortment'], a['store_type'])\n",
    "a9 = cramer_v(a['assortment'], a['assortment'])\n",
    "\n",
    "# final dataset\n",
    "d = pd.DataFrame({'state_holiday':[a1,a2,a3], \n",
    "                  'store_type':[a4,a5,a6],\n",
    "                  'assortment':[a7,a8,a9] })\n",
    "\n",
    "d = d.set_index(d.columns)\n",
    "sns.heatmap(d, annot=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 5. DATA PREPARATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T09:36:50.525846Z",
     "start_time": "2020-11-17T09:36:44.939Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df5 = df4.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## 5.1. Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T08:14:30.818851Z",
     "start_time": "2020-11-13T08:14:27.572156Z"
    },
    "hidden": true
   },
   "source": [
    "Technique that works well for variables that have a normal distribution. As this does not occur in the numerical variables presented, this technique **will not be applied in this case**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## 5.2. Rescaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T09:36:50.527817Z",
     "start_time": "2020-11-17T09:36:44.946Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mms = MinMaxScaler()\n",
    "rs = RobustScaler()\n",
    "\n",
    "# competition_distance (Robust Scaler)\n",
    "df5['competition_distance'] = rs.fit_transform(df5[['competition_distance']].values)\n",
    "\n",
    "# competition_time_month\n",
    "df5['competition_time_month'] = rs.fit_transform(df5[['competition_time_month']].values)\n",
    "\n",
    "# promo_time_week\n",
    "df5['promo_time_week'] = mms.fit_transform(df5[['promo_time_week']].values)\n",
    "\n",
    "# year\n",
    "df5['year'] = mms.fit_transform(df5[['year']].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## 5.3. Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### 5.3.1. Response Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T09:36:50.529824Z",
     "start_time": "2020-11-17T09:36:44.952Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df5['sales'] = np.log1p(df5['sales'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### 5.3.2. Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T09:36:50.532070Z",
     "start_time": "2020-11-17T09:36:44.956Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#state_holiday - One Hot Encoder\n",
    "df5 = pd.get_dummies(df5, prefix=['state_holiday'], columns=['state_holiday'])\n",
    "\n",
    "#store_type - Label Encoder\n",
    "le = LabelEncoder()\n",
    "df5['store_type'] = le.fit_transform(df5['store_type'])\n",
    "\n",
    "# assortment - Ordinal Encoder\n",
    "assort_dict = {'basic': 1,\n",
    "               'extra': 2,\n",
    "               'extended': 3}\n",
    "df5['assortment'] = df5['assortment'].map(assort_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### 5.3.3. Nature Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T09:36:50.534061Z",
     "start_time": "2020-11-17T09:36:44.961Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# day_of_week\n",
    "df5['day_of_week_sin'] = np.sin(2 * np.pi * df5['day_of_week'] / 7) \n",
    "df5['day_of_week_cos'] = np.cos(2 * np.pi * df5['day_of_week'] / 7) \n",
    "\n",
    "# day\n",
    "df5['day_sin'] = np.sin(2 * np.pi * df5['day'] / 30) \n",
    "df5['day_cos'] = np.cos(2 * np.pi * df5['day'] / 30) \n",
    "\n",
    "# month\n",
    "df5['month_sin'] = np.sin(2 * np.pi * df5['month'] / 12) \n",
    "df5['month_cos'] = np.cos(2 * np.pi * df5['month'] / 12) \n",
    "\n",
    "# week_of_year\n",
    "df5['week_of_year_sin'] = np.sin(2 * np.pi * df5['week_of_year'] / 52) \n",
    "df5['week_of_year_cos'] = np.cos(2 * np.pi * df5['week_of_year'] / 52) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 6. FEATURE SELECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T09:36:50.535844Z",
     "start_time": "2020-11-17T09:36:44.966Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df6 = df5.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T09:36:50.538921Z",
     "start_time": "2020-11-17T09:36:44.971Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# removing colinear variables\n",
    "\n",
    "cols_drop = ['day_of_week', 'day', 'month', 'week_of_year', 'year_week', 'competition_since', 'promo_since']\n",
    "\n",
    "df6 = df6.drop(cols_drop, axis = 1)\n",
    "\n",
    "df6.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## 6.1. Split dataframe into training and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T09:36:50.542170Z",
     "start_time": "2020-11-17T09:36:44.976Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df6['date'].max() - pd.Timedelta(value = 6, unit = 'W')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T09:36:50.544393Z",
     "start_time": "2020-11-17T09:36:44.980Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# training dataset\n",
    "X_train = df6[df6['date'] < '2015-06-19']\n",
    "y_train = X_train['sales']\n",
    "\n",
    "print('Training Min Date: {}'.format(X_train['date'].min()))\n",
    "print('Training Max Date: {}'.format(X_train['date'].max()))\n",
    "\n",
    "\n",
    "# test dataset\n",
    "X_test = df6[df6['date'] >= '2015-06-19']\n",
    "y_test = X_test['sales']\n",
    "\n",
    "print('\\nTest Min Date: {}'.format(X_test['date'].min()))\n",
    "print('Test Max Date: {}'.format(X_test['date'].max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## 6.2. Boruta as Feature Selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T09:36:50.546251Z",
     "start_time": "2020-11-17T09:36:44.985Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# # conversion of df/series to numpy and remotion of variables that do not compose training ('sales' and 'date')\n",
    "# x_train_n = X_train.drop(['sales', 'date'], axis=1).values\n",
    "# y_train_n = y_train.values.ravel()\n",
    "\n",
    "# # define RandomForestRegressor\n",
    "# rf = RandomForestRegressor(n_jobs = -1)\n",
    "\n",
    "# # define Boruta\n",
    "# boruta = BorutaPy(rf, n_estimators = 'auto', verbose = 2, random_state = 42).fit(x_train_n, y_train_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### 6.2.1. Best Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T09:36:50.548340Z",
     "start_time": "2020-11-17T09:36:44.990Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# cols_selected = boruta.support_.tolist()\n",
    "\n",
    "# # best features\n",
    "# X_train_fs = X_train.drop(['sales', 'date'], axis = 1)\n",
    "# cols_selected_boruta = X_train_fs.iloc[:, cols_selected].columns.tolist()\n",
    "\n",
    "# # colunas desconsideradas pelo boruta\n",
    "# cols_not_selected_boruta = list(np.setdiff1d(X_train_fs.columns, cols_selected_boruta))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## 6.3. Saving Boruta Best Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T09:36:50.550604Z",
     "start_time": "2020-11-17T09:36:44.995Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cols_selected_boruta = [\n",
    " 'store',\n",
    " 'promo',\n",
    " 'store_type',\n",
    " 'assortment',\n",
    " 'competition_distance',\n",
    " 'competition_open_since_month',\n",
    " 'competition_open_since_year',\n",
    " 'promo2',\n",
    " 'promo2_since_week',\n",
    " 'promo2_since_year',\n",
    " 'competition_time_month',\n",
    " 'promo_time_week',\n",
    " 'month_cos',\n",
    " 'month_sin',\n",
    " 'day_sin',\n",
    " 'day_cos',\n",
    " 'week_of_year_cos',\n",
    " 'day_of_week_sin',\n",
    " 'day_of_week_cos']\n",
    "\n",
    "#columns to add\n",
    "feat_to_add = ['date', 'sales']\n",
    "\n",
    "#final features\n",
    "cols_selected_boruta_full = cols_selected_boruta.copy()\n",
    "cols_selected_boruta_full.extend( feat_to_add )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 7. MACHINE LEARNING MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T09:36:50.557683Z",
     "start_time": "2020-11-17T09:36:45.001Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x_train = X_train[cols_selected_boruta]\n",
    "x_test = X_test[cols_selected_boruta]\n",
    "\n",
    "# Time Series Cross-Validation\n",
    "x_training = X_train[cols_selected_boruta_full]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## 7.1. Average Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T09:36:50.559772Z",
     "start_time": "2020-11-17T09:36:45.007Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# test dataset\n",
    "aux1 = x_test.copy()\n",
    "aux1['sales'] = y_test.copy()\n",
    "\n",
    "# prediction\n",
    "aux2 = aux1[['store', 'sales']].groupby('store').mean().reset_index().rename(columns = {'sales': 'predictions'})\n",
    "aux1 = pd.merge(aux1, aux2, how = 'left', on = 'store')\n",
    "yhat_baseline = aux1['predictions']\n",
    "\n",
    "# performance\n",
    "baseline_result = ml_error('Average Model', np.expm1(y_test), np.expm1(yhat_baseline))\n",
    "baseline_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## 7.2. Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T09:36:50.561738Z",
     "start_time": "2020-11-17T09:36:45.012Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# model\n",
    "lr = LinearRegression().fit(x_train, y_train)\n",
    "\n",
    "# predicition\n",
    "yhat_lr = lr.predict(x_test)\n",
    "\n",
    "# performance\n",
    "lr_result = ml_error('Linear Regression', np.expm1(y_test), np.expm1(yhat_lr))\n",
    "lr_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### 7.1.2.  Linear Regression Model - Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T09:36:50.563878Z",
     "start_time": "2020-11-17T09:36:45.017Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lr_result_cv = cross_validation(x_training, 5, 'Linear Regression', lr, verbose=True)\n",
    "lr_result_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## 7.3. Linear Regression Regularized Model (Lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T09:36:50.568307Z",
     "start_time": "2020-11-17T09:36:45.026Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# model\n",
    "lrr = Lasso(alpha = 0.01).fit(x_train, y_train)\n",
    "\n",
    "# predicition\n",
    "yhat_lrr = lrr.predict(x_test)\n",
    "\n",
    "# performance\n",
    "lrr_result = ml_error('Lasso', np.expm1(y_test), np.expm1(yhat_lrr))\n",
    "lrr_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### 7.1.3.  Lasso - Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T09:36:50.571198Z",
     "start_time": "2020-11-17T09:36:45.032Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lrr_result_cv = cross_validation(x_training, 5, 'Lasso', lrr, verbose=False)\n",
    "lrr_result_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## 7.4. Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T09:36:50.573302Z",
     "start_time": "2020-11-17T09:36:45.037Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# model\n",
    "rf = RandomForestRegressor(n_estimators = 100, n_jobs = -1, random_state = 42).fit(x_train, y_train)\n",
    "\n",
    "# predicition\n",
    "yhat_rf = rf.predict(x_test)\n",
    "\n",
    "# performance\n",
    "rf_result = ml_error('Random Forest Regressor', np.expm1(y_test), np.expm1(yhat_rf))\n",
    "rf_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### 7.1.4. Random Forest Regressor - Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "rf_result_cv = cross_validation(x_training, 5, 'Random Forest Regressor', rf, verbose=False)\n",
    "rf_result_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## 7.5. XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T09:36:50.575378Z",
     "start_time": "2020-11-17T09:36:45.043Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# model\n",
    "model_xgb = xgb().fit(x_train, y_train)\n",
    "\n",
    "# predicition\n",
    "yhat_xgb = model_xgb.predict(x_test)\n",
    "\n",
    "# performance\n",
    "xgb_result = ml_error('XGBoost Regressor', np.expm1(y_test), np.expm1(yhat_rf))\n",
    "xgb_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### 7.1.5. XGBoost Regressor - Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "xgb_result_cv = cross_validation(x_training, 5, 'XGBoost Regressor', model_xgb, verbose=False)\n",
    "xgb_result_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## 7.6. Compare Model's Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### 7.6.1. Single Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "modelling_result = pd.concat([baseline_result, lr_result, lrr_result, rf_result, xgb_result])\n",
    "modelling_result.sort_values('RMSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### 7.6.2. Real Performance (Cross Validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "modelling_result_cv = pd.concat([lr_result_cv, lrr_result_cv, rf_result_cv, xgb_result_cv])\n",
    "modelling_result_cv.sort_values('RMSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 8. HYPERPARAMETER FINE TUNING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## 8.1. Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "param = ('n_estimators': [1500, 1700, 2500, 3000, 3500],\n",
    "         'eta': [0.01, 0.03],\n",
    "         'max_depth': [3, 5, 9],\n",
    "         'subsample': [0.1, 0.5, 0.7],\n",
    "         'colsample_bytree': [0.3, 0.7, 0.9],\n",
    "         'min_child_weight': [3, 8, 15])\n",
    "\n",
    "MAX_EVAL = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "final_result = pd.DataFrame()\n",
    "\n",
    "for i in range (MAX_EVAL):\n",
    "    # choose values for parameters randomly\n",
    "    hp = (k: random.sample(v, 1)[0] for k, v in param.items())\n",
    "    print(hp)\n",
    "    \n",
    "    # model\n",
    "    model_xgb = xgb.XGBRegressor(objective = 'reg:squarederror',\n",
    "                                 n_estimators = hp['n_estimators'],\n",
    "                                 eta = hp['eta'],\n",
    "                                 max_depth = hp['max_depth'],\n",
    "                                 subsample = hp['subsample'],\n",
    "                                 colsample_bytee = hp['colsample_bytree'],\n",
    "                                 min_child_weight = hp['min_child_weight'])\n",
    "    \n",
    "    # prediction\n",
    "    yhat_xgb = model_xgb.predict(x_test)\n",
    "    \n",
    "    # performance    \n",
    "    result = cross_validation (x_training, 2, 'XGBoost Regressor', model_xgb, verbose=False)\n",
    "    final_result = pd.concat([final_result, result])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## 8.2. Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "param_tuned = {'n_estimators': 3500,\n",
    "               'eta': 0.01,\n",
    "               'max_depth': 5,\n",
    "               'subsample': 0.5,\n",
    "               'colsample_bytree': 0.7,\n",
    "               'min_child_weight': 15}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# model\n",
    "model_xgb_tuned = xgb.XGBRegressor(objective = 'reg:squarederror',\n",
    "                                   n_estimators = param_tuned['n_estimators'],\n",
    "                                   eta = param_tuned['eta'],\n",
    "                                   max_depth = param_tuned['max_depth'],\n",
    "                                   subsample = param_tuned['subsample'],\n",
    "                                   colsample_bytee = param_tuned['colsample_bytree'],\n",
    "                                   min_child_weight = param_tuned['min_child_weight']).fit(x_train, Y_train)\n",
    "\n",
    "# prediction\n",
    "yhat_xgb_tuned = model_xgb_tuned.predict(x_test)\n",
    "\n",
    "# performance    \n",
    "xgb_result_tuned = ml_error('XGBoost Regressor', np.expm1(Y_test), np.expm1(yhat_xgb_tuned))\n",
    "xgb_result_tuned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 9. ERROR INTERPRETATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df9 = X_test[cols_selected_boruta_full]\n",
    "\n",
    "# rescale\n",
    "df9['sales'] = np.expm1(df9['sales'])\n",
    "df9['predictions'] = np.expm1( yhat_xgb_tuned )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## 9.1. Business Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# sum of predictions\n",
    "df91 = df9[['store', 'predictions']].groupby('store').sum().reset_index()\n",
    "\n",
    "# MAE and MAPE\n",
    "df9_aux1 = df9[['store', 'sales', 'predictions']].groupby('store').apply(lambda x: mean_absolute_error( x['sales'], x['predictions'])).reset_index().rename( columns={0:'MAE'} )\n",
    "df9_aux2 = df9[['store', 'sales', 'predictions']].groupby('store').apply(lambda x: mean_absolute_percentage_error( x['sales'], x['predictions'])).reset_index().rename( columns={0:'MAPE'} )\n",
    "\n",
    "# merge\n",
    "df9_aux3 = pd.merge ( df9_aux1, df9_aux2, how='inner', on='store')\n",
    "df92 = pd.merge( df91, df9_aux3, how='inner', on='store')\n",
    "\n",
    "# scenarios\n",
    "df92['worst_scenario'] = df92['predictions'] - df92['MAE']\n",
    "df92['best_scenario'] = df92['predictions'] + df92['MAE']\n",
    "\n",
    "\n",
    "# order columns\n",
    "df92 = df92[['store', 'predictions', 'worst_scenario', 'best_scenario', 'MAE', 'MAPE']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Stores with more difficult prediction evaluation\n",
    "df92.sort_values('MAPE', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Scatterplot visualization\n",
    "sns.scatterplot(x='store', y='MAPE', data=df92)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## 9.2. Total Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df93 = df92[['predictions', 'worst_scenario', 'best_scenario']].apply(lambda x: np.sum(x), axis=0).reset_index().rename( columns={'index': 'Scenario', 0:'Values'})\n",
    "df93['Values'] = df93['Values'].map( '${:,.2f}'.format )\n",
    "df93"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## 9.3. Machine Learning Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df7['error'] = df7['sales'] - df7['predictions']\n",
    "\n",
    "df7['error_rate'] = df7['predictions'] / df7['sales']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sns.lineplot(x='date', y='sales', data=df7, label='Sales');\n",
    "sns.lineplot(x='date', y='predictions', data=df7, label='Predictions');\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "sns.lineplot(x='date', y='error_rate', data=df7);\n",
    "plt.axhline(1, linestyle = '--');\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "sns.distplot(df7['error']);\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "sns.scatterplot(df7['predictions'], df7['error']);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
